skp-kafka-node
===============
<blockquote>
Exposes basic kafka functionality - initProducer, write to topic, read from topic (by opening a listening) and commit offset.
</blockquote>

## In order to write:
1.  require skp-kafka-node
2.  create kafkaClient configuration JSON
3.  work with async/await syntax or with promise syntax (.then, .catch)
4.  init the producer with kafkaClient configurations and partitioner type (optional)
5.  use writeToTopic function
6.  close the producer if needed

## In order to read:
1.  create kafkaConsumerGroup configurations
2.  creare callBack, error function
3.  use listenToTopic with your consumer group configurations
4.  for each message that arrive, callBack function will execute
## Configurations example: 
check [node-seed-service](https://bitbucket.app.iaf/projects/SP/repos/node-seed-service/browse).

## Usage examples:

```javascript
const skpKafka = require('skp-kafka-node');
const clientOptions = require('./kafka-client-configurations');
const cgOptions = require('./kafka-consumer-group-configurations');

(async() => {
    try {
        const producer = await skpKafka.initProducer(clientOptions, 2);
        await skpKafka.writeToTopic(producer, {test: 'test'}, 'Topic.t');
        producer.close();
    } catch(err) {
        console.log(err);
    }
})();
 

skpKafka.listenToTopic('Topic.t', 'gropId', cgOptions, commitAndPrint, (err) => console.log(err));

// example of callBack function, optional - you can commit at any point (if auto commit is false)
async function commitAndPrint(data) {
        await skpKafka.commitOffset(data);
        console.log(data);
}
```
